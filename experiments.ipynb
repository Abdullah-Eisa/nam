{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_boston(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2137)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype('float32'))\n",
    "X_test = torch.from_numpy(X_test.astype('float32'))\n",
    "y_train = torch.from_numpy(y_train.reshape(-1, 1).astype('float32'))\n",
    "y_test = torch.from_numpy(y_test.reshape(-1, 1).astype('float32'))\n",
    "\n",
    "dataset_train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "dataset_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = next(iter(dataset_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 13]), torch.Size([64, 1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (layer1): Linear(in_features=13, out_features=32, bias=True)\n",
       "  (layer2): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (layer3): Linear(in_features=16, out_features=12, bias=True)\n",
       "  (layer4): Linear(in_features=12, out_features=1, bias=True)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  (dropout3): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(13, 32)\n",
    "        self.layer2 = nn.Linear(32, 16)\n",
    "        self.layer3 = nn.Linear(16, 12)\n",
    "        self.layer4 = nn.Linear(12, 1)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.layer3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_obj = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(543.9302, grad_fn=<MseLossBackward>)\n",
      "tensor(488.8261, grad_fn=<MseLossBackward>)\n",
      "tensor(770.0425, grad_fn=<MseLossBackward>)\n",
      "tensor(658.2023, grad_fn=<MseLossBackward>)\n",
      "tensor(515.4057, grad_fn=<MseLossBackward>)\n",
      "tensor(578.2120, grad_fn=<MseLossBackward>)\n",
      "tensor(591.4470, grad_fn=<MseLossBackward>)\n",
      "tensor(480.4409, grad_fn=<MseLossBackward>)\n",
      "tensor(764.2185, grad_fn=<MseLossBackward>)\n",
      "tensor(441.9752, grad_fn=<MseLossBackward>)\n",
      "tensor(445.0178, grad_fn=<MseLossBackward>)\n",
      "tensor(385.0773, grad_fn=<MseLossBackward>)\n",
      "tensor(469.6506, grad_fn=<MseLossBackward>)\n",
      "tensor(446.7991, grad_fn=<MseLossBackward>)\n",
      "tensor(491.9495, grad_fn=<MseLossBackward>)\n",
      "tensor(300.4225, grad_fn=<MseLossBackward>)\n",
      "tensor(287.5339, grad_fn=<MseLossBackward>)\n",
      "tensor(329.1008, grad_fn=<MseLossBackward>)\n",
      "tensor(275.3817, grad_fn=<MseLossBackward>)\n",
      "tensor(81.3637, grad_fn=<MseLossBackward>)\n",
      "tensor(133.9323, grad_fn=<MseLossBackward>)\n",
      "tensor(155.4055, grad_fn=<MseLossBackward>)\n",
      "tensor(142.8362, grad_fn=<MseLossBackward>)\n",
      "tensor(101.9452, grad_fn=<MseLossBackward>)\n",
      "tensor(61.6484, grad_fn=<MseLossBackward>)\n",
      "tensor(67.1702, grad_fn=<MseLossBackward>)\n",
      "tensor(93.3098, grad_fn=<MseLossBackward>)\n",
      "tensor(162.5412, grad_fn=<MseLossBackward>)\n",
      "tensor(117.0417, grad_fn=<MseLossBackward>)\n",
      "tensor(148.1261, grad_fn=<MseLossBackward>)\n",
      "tensor(105.9603, grad_fn=<MseLossBackward>)\n",
      "tensor(132.2306, grad_fn=<MseLossBackward>)\n",
      "tensor(121.9951, grad_fn=<MseLossBackward>)\n",
      "tensor(132.9101, grad_fn=<MseLossBackward>)\n",
      "tensor(77.8982, grad_fn=<MseLossBackward>)\n",
      "tensor(60.5787, grad_fn=<MseLossBackward>)\n",
      "tensor(90.4621, grad_fn=<MseLossBackward>)\n",
      "tensor(89.6737, grad_fn=<MseLossBackward>)\n",
      "tensor(104.7656, grad_fn=<MseLossBackward>)\n",
      "tensor(135.9938, grad_fn=<MseLossBackward>)\n",
      "tensor(118.1116, grad_fn=<MseLossBackward>)\n",
      "tensor(77.1041, grad_fn=<MseLossBackward>)\n",
      "tensor(106.5776, grad_fn=<MseLossBackward>)\n",
      "tensor(52.3654, grad_fn=<MseLossBackward>)\n",
      "tensor(109.6810, grad_fn=<MseLossBackward>)\n",
      "tensor(69.3717, grad_fn=<MseLossBackward>)\n",
      "tensor(104.5827, grad_fn=<MseLossBackward>)\n",
      "tensor(110.4435, grad_fn=<MseLossBackward>)\n",
      "tensor(80.1163, grad_fn=<MseLossBackward>)\n",
      "tensor(74.1190, grad_fn=<MseLossBackward>)\n",
      "tensor(106.2178, grad_fn=<MseLossBackward>)\n",
      "tensor(36.8365, grad_fn=<MseLossBackward>)\n",
      "tensor(124.6334, grad_fn=<MseLossBackward>)\n",
      "tensor(72.1062, grad_fn=<MseLossBackward>)\n",
      "tensor(106.9173, grad_fn=<MseLossBackward>)\n",
      "tensor(55.1648, grad_fn=<MseLossBackward>)\n",
      "tensor(68.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(113.2460, grad_fn=<MseLossBackward>)\n",
      "tensor(102.8465, grad_fn=<MseLossBackward>)\n",
      "tensor(67.5390, grad_fn=<MseLossBackward>)\n",
      "tensor(54.5438, grad_fn=<MseLossBackward>)\n",
      "tensor(23.1918, grad_fn=<MseLossBackward>)\n",
      "tensor(98.7916, grad_fn=<MseLossBackward>)\n",
      "tensor(77.5756, grad_fn=<MseLossBackward>)\n",
      "tensor(48.0787, grad_fn=<MseLossBackward>)\n",
      "tensor(57.6968, grad_fn=<MseLossBackward>)\n",
      "tensor(70.1253, grad_fn=<MseLossBackward>)\n",
      "tensor(67.2027, grad_fn=<MseLossBackward>)\n",
      "tensor(43.7854, grad_fn=<MseLossBackward>)\n",
      "tensor(19.5958, grad_fn=<MseLossBackward>)\n",
      "tensor(64.3488, grad_fn=<MseLossBackward>)\n",
      "tensor(50.4166, grad_fn=<MseLossBackward>)\n",
      "tensor(52.8546, grad_fn=<MseLossBackward>)\n",
      "tensor(33.9635, grad_fn=<MseLossBackward>)\n",
      "tensor(57.7867, grad_fn=<MseLossBackward>)\n",
      "tensor(113.8595, grad_fn=<MseLossBackward>)\n",
      "tensor(39.8395, grad_fn=<MseLossBackward>)\n",
      "tensor(66.3927, grad_fn=<MseLossBackward>)\n",
      "tensor(53.6288, grad_fn=<MseLossBackward>)\n",
      "tensor(49.6553, grad_fn=<MseLossBackward>)\n",
      "tensor(41.4190, grad_fn=<MseLossBackward>)\n",
      "tensor(75.2443, grad_fn=<MseLossBackward>)\n",
      "tensor(30.4734, grad_fn=<MseLossBackward>)\n",
      "tensor(68.5529, grad_fn=<MseLossBackward>)\n",
      "tensor(23.1096, grad_fn=<MseLossBackward>)\n",
      "tensor(25.7043, grad_fn=<MseLossBackward>)\n",
      "tensor(31.1375, grad_fn=<MseLossBackward>)\n",
      "tensor(65.3523, grad_fn=<MseLossBackward>)\n",
      "tensor(123.3342, grad_fn=<MseLossBackward>)\n",
      "tensor(30.3135, grad_fn=<MseLossBackward>)\n",
      "tensor(77.9802, grad_fn=<MseLossBackward>)\n",
      "tensor(47.3496, grad_fn=<MseLossBackward>)\n",
      "tensor(61.9360, grad_fn=<MseLossBackward>)\n",
      "tensor(74.8568, grad_fn=<MseLossBackward>)\n",
      "tensor(77.9745, grad_fn=<MseLossBackward>)\n",
      "tensor(42.3764, grad_fn=<MseLossBackward>)\n",
      "tensor(54.9662, grad_fn=<MseLossBackward>)\n",
      "tensor(33.9571, grad_fn=<MseLossBackward>)\n",
      "tensor(39.6001, grad_fn=<MseLossBackward>)\n",
      "tensor(23.1798, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    for X, y in dataset_train:\n",
    "        y_pred = model(X)\n",
    "        loss = loss_obj(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.506484471392474"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(X_test)\n",
    "r2_score(y_test.detach().numpy(), y_pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from loguru import logger\n",
    "\n",
    "from nam.config import defaults\n",
    "from nam.types import Config\n",
    "from nam.utils.args import parse_args\n",
    "from nam.data import NAMDataset\n",
    "from nam.models import DNN, FeatureNN, NAM, get_num_units\n",
    "from nam.engine import Engine\n",
    "\n",
    "from main import get_config\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = get_config()\n",
    "pl.seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FeatureNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Testing the `FeatureNN` network as a regular NN with input_shape 13 for the whole features and output 1\n",
    "> This is for testing `ExU` Unit and how it behave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amrmkayid/anaconda3/envs/nam/lib/python3.7/site-packages/torch/nn/init.py:162: UserWarning: mean is more than 2 std from [a, b] in nn.init.trunc_normal_. The distribution of values may be incorrect.\n",
      "  return _no_grad_trunc_normal_(tensor, mean, std, a, b)\n"
     ]
    }
   ],
   "source": [
    "fnn = FeatureNN(\n",
    "      config=config,\n",
    "      name=f'FeatureNN_{0}',\n",
    "      input_shape=13,\n",
    "      num_units=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureNN(\n",
       "  (model): Sequential(\n",
       "    (0): ExU(in_features=13, out_features=128)\n",
       "    (1): ExU(in_features=128, out_features=64)\n",
       "    (2): ExU(in_features=64, out_features=32)\n",
       "    (3): ExU(in_features=32, out_features=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_obj = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(fnn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1852e+19, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1022e+19, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9965e+19, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5021e+19, grad_fn=<MseLossBackward>)\n",
      "tensor(1.4037e+19, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0525e+19, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1914e+19, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0202e+19, grad_fn=<MseLossBackward>)\n",
      "tensor(3.8945e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(9.8691e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2846e+19, grad_fn=<MseLossBackward>)\n",
      "tensor(8.2722e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(6.0455e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(6.3798e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(4.7199e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(5.5048e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(6.4722e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(4.7808e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(5.4019e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(5.2708e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2664e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(6.1229e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(2.7402e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(3.9327e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(6.0101e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8649e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0628e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7587e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(3.6900e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5953e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(4.2594e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(4.2302e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9900e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1901e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0317e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(2.7689e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(9.9986e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5762e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6305e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0871e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7044e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7544e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9631e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2561e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1367e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1774e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5595e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1620e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(8.4938e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(1.3919e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.4628e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1765e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(6.5033e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(7.6107e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(9.5608e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0680e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.4743e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(7.1677e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(7.5615e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(5.4777e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(8.6013e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8480e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0205e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3023e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(6.7135e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(8.1818e+16, grad_fn=<MseLossBackward>)\n",
      "tensor(9.6414e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0109e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(4.3536e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(4.4571e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(6.4845e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(8.4436e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(3.8095e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7335e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(3.1631e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(4.7216e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(4.1740e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(5.0148e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(8.1562e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(4.4653e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1730e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(6.0565e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0087e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1963e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(7.5023e+16, grad_fn=<MseLossBackward>)\n",
      "tensor(6.2083e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(4.2458e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(6.5479e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4349e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.7073e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(3.9933e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7669e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(6.1773e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6491e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(7.7274e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5767e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(4.0048e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(7.3898e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(4.2536e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.8479e+15, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    for X, y in dataset_train:\n",
    "        y_pred = fnn(X)\n",
    "        loss = loss_obj(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2781243590242559.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = fnn(X_test)\n",
    "r2_score(y_test.detach().numpy(), y_pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amrmkayid/anaconda3/envs/nam/lib/python3.7/site-packages/torch/nn/init.py:162: UserWarning: mean is more than 2 std from [a, b] in nn.init.trunc_normal_. The distribution of values may be incorrect.\n",
      "  return _no_grad_trunc_normal_(tensor, mean, std, a, b)\n"
     ]
    }
   ],
   "source": [
    "model = NAM(\n",
    "      config=config,\n",
    "      name=\"NAMModel\",\n",
    "      num_inputs=X.shape[1],\n",
    "      num_units=get_num_units(config, dataset_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAM(\n",
       "  (feature_nns): Sequential(\n",
       "    (FeatureNN_0): FeatureNN(\n",
       "      (model): Sequential(\n",
       "        (0): ExU(in_features=1, out_features=128)\n",
       "        (1): ExU(in_features=128, out_features=64)\n",
       "        (2): ExU(in_features=64, out_features=32)\n",
       "        (3): ExU(in_features=32, out_features=1)\n",
       "      )\n",
       "    )\n",
       "    (FeatureNN_1): FeatureNN(\n",
       "      (model): Sequential(\n",
       "        (0): ExU(in_features=1, out_features=22)\n",
       "        (1): ExU(in_features=22, out_features=64)\n",
       "        (2): ExU(in_features=64, out_features=32)\n",
       "        (3): ExU(in_features=32, out_features=1)\n",
       "      )\n",
       "    )\n",
       "    (FeatureNN_2): FeatureNN(\n",
       "      (model): Sequential(\n",
       "        (0): ExU(in_features=1, out_features=60)\n",
       "        (1): ExU(in_features=60, out_features=64)\n",
       "        (2): ExU(in_features=64, out_features=32)\n",
       "        (3): ExU(in_features=32, out_features=1)\n",
       "      )\n",
       "    )\n",
       "    (FeatureNN_3): FeatureNN(\n",
       "      (model): Sequential(\n",
       "        (0): ExU(in_features=1, out_features=4)\n",
       "        (1): ExU(in_features=4, out_features=64)\n",
       "        (2): ExU(in_features=64, out_features=32)\n",
       "        (3): ExU(in_features=32, out_features=1)\n",
       "      )\n",
       "    )\n",
       "    (FeatureNN_4): FeatureNN(\n",
       "      (model): Sequential(\n",
       "        (0): ExU(in_features=1, out_features=80)\n",
       "        (1): ExU(in_features=80, out_features=64)\n",
       "        (2): ExU(in_features=64, out_features=32)\n",
       "        (3): ExU(in_features=32, out_features=1)\n",
       "      )\n",
       "    )\n",
       "    (FeatureNN_5): FeatureNN(\n",
       "      (model): Sequential(\n",
       "        (0): ExU(in_features=1, out_features=128)\n",
       "        (1): ExU(in_features=128, out_features=64)\n",
       "        (2): ExU(in_features=64, out_features=32)\n",
       "        (3): ExU(in_features=32, out_features=1)\n",
       "      )\n",
       "    )\n",
       "    (FeatureNN_6): FeatureNN(\n",
       "      (model): Sequential(\n",
       "        (0): ExU(in_features=1, out_features=120)\n",
       "        (1): ExU(in_features=120, out_features=64)\n",
       "        (2): ExU(in_features=64, out_features=32)\n",
       "        (3): ExU(in_features=32, out_features=1)\n",
       "      )\n",
       "    )\n",
       "    (FeatureNN_7): FeatureNN(\n",
       "      (model): Sequential(\n",
       "        (0): ExU(in_features=1, out_features=128)\n",
       "        (1): ExU(in_features=128, out_features=64)\n",
       "        (2): ExU(in_features=64, out_features=32)\n",
       "        (3): ExU(in_features=32, out_features=1)\n",
       "      )\n",
       "    )\n",
       "    (FeatureNN_8): FeatureNN(\n",
       "      (model): Sequential(\n",
       "        (0): ExU(in_features=1, out_features=18)\n",
       "        (1): ExU(in_features=18, out_features=64)\n",
       "        (2): ExU(in_features=64, out_features=32)\n",
       "        (3): ExU(in_features=32, out_features=1)\n",
       "      )\n",
       "    )\n",
       "    (FeatureNN_9): FeatureNN(\n",
       "      (model): Sequential(\n",
       "        (0): ExU(in_features=1, out_features=56)\n",
       "        (1): ExU(in_features=56, out_features=64)\n",
       "        (2): ExU(in_features=64, out_features=32)\n",
       "        (3): ExU(in_features=32, out_features=1)\n",
       "      )\n",
       "    )\n",
       "    (FeatureNN_10): FeatureNN(\n",
       "      (model): Sequential(\n",
       "        (0): ExU(in_features=1, out_features=46)\n",
       "        (1): ExU(in_features=46, out_features=64)\n",
       "        (2): ExU(in_features=64, out_features=32)\n",
       "        (3): ExU(in_features=32, out_features=1)\n",
       "      )\n",
       "    )\n",
       "    (FeatureNN_11): FeatureNN(\n",
       "      (model): Sequential(\n",
       "        (0): ExU(in_features=1, out_features=106)\n",
       "        (1): ExU(in_features=106, out_features=64)\n",
       "        (2): ExU(in_features=64, out_features=32)\n",
       "        (3): ExU(in_features=32, out_features=1)\n",
       "      )\n",
       "    )\n",
       "    (FeatureNN_12): FeatureNN(\n",
       "      (model): Sequential(\n",
       "        (0): ExU(in_features=1, out_features=126)\n",
       "        (1): ExU(in_features=126, out_features=64)\n",
       "        (2): ExU(in_features=64, out_features=32)\n",
       "        (3): ExU(in_features=32, out_features=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_obj = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5366e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(3.6781e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(3.3963e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(3.1029e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(3.1192e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0629e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4752e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3378e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(2.8230e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9054e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6843e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7714e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0693e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.4068e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2338e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2380e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7876e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0749e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(8.8272e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5735e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0268e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1852e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.3541e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1919e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(9.4873e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(9.0786e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(9.8359e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(8.6165e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(7.6364e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(6.1471e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(9.8274e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1076e+18, grad_fn=<MseLossBackward>)\n",
      "tensor(7.2174e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(5.5052e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(6.6054e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(6.6360e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(5.9308e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(5.1515e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(7.6603e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(6.2424e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(5.5178e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(5.9959e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(6.5593e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(4.4719e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(6.2631e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(5.5544e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(6.6737e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(4.0386e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(5.9265e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(6.8198e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(4.4567e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(5.1454e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(3.3402e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(3.5237e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(3.7212e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3706e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(3.9022e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(4.4832e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.6065e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(5.0443e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(4.7966e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(4.1188e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(4.4690e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(4.1505e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(3.1823e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(3.2537e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(3.5179e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4659e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.8222e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(3.3503e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(4.0260e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(3.3992e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(3.5109e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.6822e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.9795e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5507e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.9136e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.9690e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1493e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.6114e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(4.6569e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(3.3503e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2456e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0239e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5901e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.6307e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7746e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3303e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6814e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1747e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0961e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7092e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0317e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6205e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7341e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(1.3369e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9973e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3096e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9366e+17, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2208e+17, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    for X, y in dataset_train:\n",
    "        y_pred = model(X)\n",
    "        loss = loss_obj(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1684725260964761.8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(X_test)\n",
    "r2_score(y_test.detach().numpy(), y_pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
